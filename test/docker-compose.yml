version: '3'

x-deploy: &default-deploy
  replicas: 1
  restart_policy:
    condition: on-failure

x-deploy-manager: &default-deploy-manager
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==manager"

x-deploy-worker: &default-deploy-worker
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==worker"


services:
  spark-master:
    image: bde2020/spark-master:2.2.0-hadoop2.8-hive-java8
    networks:
      - workbench
    deploy:
      replicas: 1
      mode: replicated
      restart_policy:
        condition: on-failure
      labels:
        traefik.docker.network: workbench
        traefik.port: 8080
    env_file:
      - ./hadoop.env

  spark-worker:
    image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8
    networks:
      - workbench
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      labels:
        traefik.docker.network: workbench
        traefik.port: 8081
    env_file:
      - ./hadoop.env

  visualizer:
    image: dockersamples/visualizer:latest
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    ports:
      - "80:8080"
    deploy: *default-deploy-manager

  streaming:
    image: streaming_image
    depends_on: 
      - sparkmaster
      - sparkworker
      - dashboards
      - twitter
    extra_hosts:
      - "streaming:0.0.0.0"
    ports:
      - "5005:5005"
      - "41100:41100"
    deploy: *default-deploy-worker
    networks:
      - workbench

  dashboards:
    image: dashboards_image
    extra_hosts:
      - "dashboards:0.0.0.0"
    ports:
      - "5009:5009"
    deploy: *default-deploy-worker
    networks:
      - workbench

  twitter:
    image: twitter_image
    extra_hosts:
      - "twitter:0.0.0.0"
    ports:
      - "9017:9017"
    deploy: *default-deploy-worker
    networks:
      - workbench

networks:
  workbench:
    external: true