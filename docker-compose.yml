version: "3.8"

x-deploy: &default-deploy
  replicas: 1
  restart_policy:
    condition: on-failure

x-deploy-manager: &default-deploy-manager
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==manager"

x-deploy-worker: &default-deploy-worker
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==worker"

services:
  visualizer:
    image: dockersamples/visualizer:latest
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    ports:
      - "80:8080"
    deploy: *default-deploy-manager

  sparkmaster:
    image: jonatasmiguel/spark_image:latest
    ports:
      - "4040:4040"
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_ROLE=master
    deploy: *default-deploy-manager
    networks:
      - cluster_network
    volumes:
      - global-volume:/checkpoint

  sparkworker:
    image: jonatasmiguel/spark_image:latest
    entrypoint: dockerize -wait tcp://sparkmaster:7077 -timeout 240s /sbin/my_init
    ports:
      - "8081:8081"
      - "41352:41352"
    environment:
      - SPARK_MASTER=sparkmaster
      - SPARK_ROLE=slave
    deploy: *default-deploy-worker
    networks:
      - cluster_network
    volumes:
      - global-volume:/checkpoint

  streaming:
    image: jonatasmiguel/streaming_image:latest
    depends_on: 
      - sparkmaster
      - sparkworker
      - dashboards
      - twitter
      - namenode
      - datanode-0
    extra_hosts:
      - "streaming:0.0.0.0"
    ports:
      - "5005:5005"
      - "41100:41100"
    deploy: *default-deploy-worker
    networks:
      - cluster_network
    volumes:
      - global-volume:/checkpoint

  dashboards:
    image: jonatasmiguel/dashboards_image:latest
    extra_hosts:
      - "dashboards:0.0.0.0"
    ports:
      - "5009:5009"
    deploy: *default-deploy-worker
    networks:
      - cluster_network

  twitter:
    image: jonatasmiguel/twitter_image:latest
    extra_hosts:
      - "twitter:0.0.0.0"
    ports:
      - "9017:9017"
    deploy: *default-deploy-worker
    networks:
      - cluster_network

  namenode:
    image: gradiant/hdfs:latest
    volumes:
      - name:/hadoop/dfs
    command:
      - namenode
    environment:
      - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
      - HDFS_CONF_dfs_permissions=false
      - HDFS_CONF_dfs_client_use_datanode_hostname=true
      - HDFS_CONF_dfs_datanode_use_datanode_hostname=true
    ports:
      - 8020:8020
      - 50070:50070
      - 9870:9870
      - 50470:50470
    networks:
      - cluster_network
    deploy: 
      placement:
        constraints:
          - "node.role==manager"
      replicas: 1
     
  datanode-0:
    image: gradiant/hdfs:latest
    depends_on: 
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - data-0:/hadoop/dfs
    ports:
      - 50010:50010 
      - 1019:1019 
      - 50020:50020 
      - 8019:8019 
      - 50075:50075
      - 50475:50475
      - 1022:1022
    command:
      - datanode
    networks:
     - cluster_network  
    deploy:   
      placement:
        constraints:
          - "node.role==worker"
      replicas: 1
      
      
networks:
  cluster_network:
    attachable: true
    ipam:
       driver: default
    

volumes:
  global-volume:
  data-0:
  data-1:
  name: